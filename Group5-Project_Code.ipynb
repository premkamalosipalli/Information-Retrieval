{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44ba8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59dd5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess text data\n",
    "def preprocess(text):\n",
    "    # tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if not token in stop_words]\n",
    "    # lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # return the preprocessed text as a string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04568964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the cosine similarity between a document and a query\n",
    "def calculate_similarity(query, document):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    # calculate the tf-idf scores for the query and document\n",
    "    tfidf_query = tfidf_vectorizer.fit_transform([query])\n",
    "    tfidf_doc = tfidf_vectorizer.transform([document])\n",
    "    # calculate the cosine similarity between the query and document\n",
    "    cosine_sim = cosine_similarity(tfidf_query, tfidf_doc)[0][0]\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65887e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to group documents/web pages based on their similarity to the query\n",
    "def group_documents(query, documents):\n",
    "    # initialize the clusters\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    cluster3 = []\n",
    "    # loop through each document\n",
    "    for document in documents:\n",
    "        # preprocess the document\n",
    "        document_preprocessed = preprocess(document)\n",
    "        # calculate the similarity between the query and document\n",
    "        similarity = calculate_similarity(query, document_preprocessed)\n",
    "        # group the document into the appropriate cluster based on the number of terms that match\n",
    "        if similarity == 1:\n",
    "            cluster1.append(document)\n",
    "        elif similarity > 0 and similarity < 1:\n",
    "            cluster2.append(document)\n",
    "        else:\n",
    "            cluster3.append(document)\n",
    "    # return the clusters\n",
    "    return cluster1, cluster2, cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d47c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rank the documents in each cluster based on their similarity to the query\n",
    "def rank_documents(query, cluster):\n",
    "    # initialize the dictionary to store the document and its similarity score\n",
    "    documents_similarity = {}\n",
    "    # preprocess the query\n",
    "    query_preprocessed = preprocess(query)\n",
    "    # loop through each document in the cluster\n",
    "    for document in cluster:\n",
    "        # preprocess the document\n",
    "        document_preprocessed = preprocess(document)\n",
    "        # calculate the similarity between the query and document\n",
    "        similarity = calculate_similarity(query_preprocessed, document_preprocessed)\n",
    "        # add the document and its similarity score to the dictionary\n",
    "        documents_similarity[document] = similarity\n",
    "    # rank the documents based on their similarity score and return the ranked list\n",
    "    ranked_documents = sorted(documents_similarity, key=documents_similarity.get, reverse=True)\n",
    "    return ranked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4934d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Documents:\n",
      "\n",
      "D: Data Mining (Concepts and Techniques)\n",
      "A: Introduction to Data Science\n",
      "B: Data Science for Business\n",
      "C: Python for Data Science Handbook\n"
     ]
    }
   ],
   "source": [
    "# sample usage\n",
    "query = \"Q: data science\"\n",
    "documents = [\"A: Introduction to Data Science\", \"B: Data Science for Business\", \n",
    "             \"C: Python for Data Science Handbook\", \"D: Data Mining (Concepts and Techniques)\"]\n",
    "cluster1, cluster2, cluster3 = group_documents(query, documents)\n",
    "ranked_cluster1 = rank_documents(query, cluster1)\n",
    "ranked_cluster2 = rank_documents(query, cluster2)\n",
    "ranked_cluster3 = rank_documents(query, cluster3)\n",
    "ranked_documents = ranked_cluster1 + ranked_cluster2 + ranked_cluster3\n",
    "print(\"Ranked Documents:\\n\")\n",
    "for document in ranked_documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bafbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
